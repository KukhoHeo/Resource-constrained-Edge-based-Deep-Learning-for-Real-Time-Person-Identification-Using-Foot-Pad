{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e4597dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from model import *\n",
    "import random\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "data=np.load(\"data/data.npz\")\n",
    "foot=data['arr_0']\n",
    "target=data['arr_1']\n",
    "foot=foot/255\n",
    "random_state=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28e0bcf0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 ListWrapper([1, 1])\n",
      "16 ListWrapper([1, 1])\n",
      "32 ListWrapper([2, 1])\n",
      "32 ListWrapper([1, 1])\n",
      "64 ListWrapper([2, 1])\n",
      "64 ListWrapper([1, 1])\n",
      "128 ListWrapper([2, 1])\n",
      "128 ListWrapper([1, 1])\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method ResnetBlock.call of <model.ResnetBlock object at 0x7f1d586ac4c0>> and will run it as-is.\n",
      "Cause: mangled names are not yet supported\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method ResnetBlock.call of <model.ResnetBlock object at 0x7f1d586ac4c0>> and will run it as-is.\n",
      "Cause: mangled names are not yet supported\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-16 05:53:56.813428: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-16 05:53:57.444337: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:222] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-01-16 05:53:57.444475: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 23440 MB memory:  -> device: 0, name: Tesla V100-DGXS-32GB, pci bus id: 0000:07:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"subclassing_model3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " layer_in (InputLayer)       [(None, 48, 48, 1)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 24, 24, 16)        800       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 24, 24, 16)       64        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " tf.nn.relu (TFOpLambda)     (None, 24, 24, 16)        0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 12, 12, 16)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " resnet_block (ResnetBlock)  (None, 12, 12, 16)        4768      \n",
      "                                                                 \n",
      " resnet_block_1 (ResnetBlock  (None, 12, 12, 16)       4768      \n",
      " )                                                               \n",
      "                                                                 \n",
      " resnet_block_2 (ResnetBlock  (None, 6, 6, 32)         14816     \n",
      " )                                                               \n",
      "                                                                 \n",
      " resnet_block_3 (ResnetBlock  (None, 6, 6, 32)         18752     \n",
      " )                                                               \n",
      "                                                                 \n",
      " resnet_block_4 (ResnetBlock  (None, 3, 3, 64)         58304     \n",
      " )                                                               \n",
      "                                                                 \n",
      " resnet_block_5 (ResnetBlock  (None, 3, 3, 64)         74368     \n",
      " )                                                               \n",
      "                                                                 \n",
      " resnet_block_6 (ResnetBlock  (None, 2, 2, 128)        231296    \n",
      " )                                                               \n",
      "                                                                 \n",
      " resnet_block_7 (ResnetBlock  (None, 2, 2, 128)        296192    \n",
      " )                                                               \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 128)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 25)                3225      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 707,353\n",
      "Trainable params: 704,953\n",
      "Non-trainable params: 2,400\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=ResNet18(25)\n",
    "\n",
    "\n",
    "def get_functional_model(model):\n",
    "    # 이 코드는「이전 포스팅의 Functional API」와 거의 동일\n",
    "    x = keras.layers.Input(shape=(48,48,1), name='layer_in')\n",
    "    temp_model = tf.keras.Model(\n",
    "        inputs=[x],\n",
    "        outputs=model.call(x),  # ※서브 클래스화한 모델의 'call'메소드를 지정\n",
    "        name='subclassing_model3')  # 임의의 모델에도 이름을 붙인다.\n",
    "    return temp_model\n",
    "\n",
    "# Functional API의「임의의 모델」을 취득\n",
    "f_model = get_functional_model(model)\n",
    "\n",
    "# 모델의 내용을 출력\n",
    "f_model.summary()\n",
    "model.build(input_shape = (None,48,48,1))\n",
    "model.compile(optimizer = \"adam\",loss='categorical_crossentropy', metrics=[\"accuracy\"]) \n",
    "from keras.utils.vis_utils import plot_model\n",
    "plot_model(model, show_shapes=True, show_layer_names=False)\n",
    "# import visualkeras\n",
    "# visualkeras.layered_view(model,legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c811c7c2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version =  2.9.1\n",
      "keras version =  2.9.0\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-02 08:41:29.384861: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-02 08:41:30.004920: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:222] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-01-02 08:41:30.005060: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30429 MB memory:  -> device: 0, name: Tesla V100-DGXS-32GB, pci bus id: 0000:07:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 48, 48, 8)         80        \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 48, 48, 8)         584       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 24, 24, 8)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 24, 24, 16)        1168      \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 24, 24, 16)        2320      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 12, 12, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 12, 12, 32)        4640      \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 12, 12, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 12, 12, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 6, 6, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 6, 6, 64)          18496     \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 6, 6, 64)          36928     \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 6, 6, 64)          36928     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 3, 3, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 3, 3, 64)          36928     \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 3, 3, 64)          36928     \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 3, 3, 64)          36928     \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 1, 1, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               16640     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 25)                3225      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 283,185\n",
      "Trainable params: 283,185\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-02 08:41:32.616250: I tensorflow/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137/137 [==============================] - 6s 22ms/step - loss: 3.1645 - accuracy: 0.0553 - val_loss: 2.8053 - val_accuracy: 0.1140\n",
      "Epoch 2/1000\n",
      "137/137 [==============================] - 2s 16ms/step - loss: 2.3846 - accuracy: 0.2309 - val_loss: 2.0242 - val_accuracy: 0.3208\n",
      "Epoch 3/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 1.8431 - accuracy: 0.3809 - val_loss: 1.7378 - val_accuracy: 0.4068\n",
      "Epoch 4/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 1.6795 - accuracy: 0.4358 - val_loss: 1.6224 - val_accuracy: 0.4640\n",
      "Epoch 5/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 1.5709 - accuracy: 0.4737 - val_loss: 1.5216 - val_accuracy: 0.5004\n",
      "Epoch 6/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 1.5168 - accuracy: 0.4873 - val_loss: 1.5395 - val_accuracy: 0.4784\n",
      "Epoch 7/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 1.4415 - accuracy: 0.5139 - val_loss: 1.4241 - val_accuracy: 0.5244\n",
      "Epoch 8/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 1.4046 - accuracy: 0.5196 - val_loss: 1.4058 - val_accuracy: 0.5148\n",
      "Epoch 9/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 1.3249 - accuracy: 0.5466 - val_loss: 1.3657 - val_accuracy: 0.5312\n",
      "Epoch 10/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 1.2903 - accuracy: 0.5598 - val_loss: 1.3014 - val_accuracy: 0.5532\n",
      "Epoch 11/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 1.2368 - accuracy: 0.5773 - val_loss: 1.3241 - val_accuracy: 0.5364\n",
      "Epoch 12/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 1.1959 - accuracy: 0.5909 - val_loss: 1.2003 - val_accuracy: 0.5988\n",
      "Epoch 13/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 1.1647 - accuracy: 0.6003 - val_loss: 1.2107 - val_accuracy: 0.5876\n",
      "Epoch 14/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 1.1292 - accuracy: 0.6125 - val_loss: 1.2000 - val_accuracy: 0.5872\n",
      "Epoch 15/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 1.0826 - accuracy: 0.6297 - val_loss: 1.1526 - val_accuracy: 0.6072\n",
      "Epoch 16/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 1.0414 - accuracy: 0.6445 - val_loss: 1.1040 - val_accuracy: 0.6272\n",
      "Epoch 17/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 1.0257 - accuracy: 0.6484 - val_loss: 1.1598 - val_accuracy: 0.6008\n",
      "Epoch 18/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.9694 - accuracy: 0.6714 - val_loss: 1.0688 - val_accuracy: 0.6392\n",
      "Epoch 19/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.9429 - accuracy: 0.6786 - val_loss: 1.0040 - val_accuracy: 0.6620\n",
      "Epoch 20/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 0.9021 - accuracy: 0.6927 - val_loss: 0.9914 - val_accuracy: 0.6636\n",
      "Epoch 21/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.8614 - accuracy: 0.7089 - val_loss: 0.9399 - val_accuracy: 0.6796\n",
      "Epoch 22/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.8306 - accuracy: 0.7167 - val_loss: 0.9266 - val_accuracy: 0.6912\n",
      "Epoch 23/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 0.7963 - accuracy: 0.7311 - val_loss: 0.9492 - val_accuracy: 0.6872\n",
      "Epoch 24/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 0.7543 - accuracy: 0.7446 - val_loss: 0.8247 - val_accuracy: 0.7356\n",
      "Epoch 25/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 0.7261 - accuracy: 0.7554 - val_loss: 0.8509 - val_accuracy: 0.7188\n",
      "Epoch 26/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.7038 - accuracy: 0.7629 - val_loss: 0.8061 - val_accuracy: 0.7336\n",
      "Epoch 27/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.6750 - accuracy: 0.7705 - val_loss: 0.8006 - val_accuracy: 0.7252\n",
      "Epoch 28/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.6344 - accuracy: 0.7887 - val_loss: 0.7208 - val_accuracy: 0.7604\n",
      "Epoch 29/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.6089 - accuracy: 0.7937 - val_loss: 0.7441 - val_accuracy: 0.7568\n",
      "Epoch 30/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.5903 - accuracy: 0.8003 - val_loss: 0.7188 - val_accuracy: 0.7676\n",
      "Epoch 31/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.5748 - accuracy: 0.8063 - val_loss: 0.7672 - val_accuracy: 0.7580\n",
      "Epoch 32/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.5700 - accuracy: 0.8063 - val_loss: 0.6666 - val_accuracy: 0.7788\n",
      "Epoch 33/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.5080 - accuracy: 0.8295 - val_loss: 0.6510 - val_accuracy: 0.7868\n",
      "Epoch 34/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.5230 - accuracy: 0.8229 - val_loss: 0.6152 - val_accuracy: 0.8036\n",
      "Epoch 35/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.4897 - accuracy: 0.8331 - val_loss: 0.6090 - val_accuracy: 0.8060\n",
      "Epoch 36/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.4742 - accuracy: 0.8403 - val_loss: 0.6011 - val_accuracy: 0.8048\n",
      "Epoch 37/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.4718 - accuracy: 0.8411 - val_loss: 0.5817 - val_accuracy: 0.8096\n",
      "Epoch 38/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.4439 - accuracy: 0.8507 - val_loss: 0.6412 - val_accuracy: 0.7888\n",
      "Epoch 39/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.4127 - accuracy: 0.8598 - val_loss: 0.6269 - val_accuracy: 0.8020\n",
      "Epoch 40/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.4117 - accuracy: 0.8612 - val_loss: 0.5702 - val_accuracy: 0.8260\n",
      "Epoch 41/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.3962 - accuracy: 0.8676 - val_loss: 0.5499 - val_accuracy: 0.8308\n",
      "Epoch 42/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.3726 - accuracy: 0.8754 - val_loss: 0.5393 - val_accuracy: 0.8324\n",
      "Epoch 43/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.3543 - accuracy: 0.8813 - val_loss: 0.5516 - val_accuracy: 0.8204\n",
      "Epoch 44/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.3396 - accuracy: 0.8862 - val_loss: 0.5681 - val_accuracy: 0.8176\n",
      "Epoch 45/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.3207 - accuracy: 0.8941 - val_loss: 0.4805 - val_accuracy: 0.8596\n",
      "Epoch 46/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.3286 - accuracy: 0.8912 - val_loss: 0.6006 - val_accuracy: 0.8120\n",
      "Epoch 47/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.3407 - accuracy: 0.8829 - val_loss: 0.4928 - val_accuracy: 0.8436\n",
      "Epoch 48/1000\n",
      "137/137 [==============================] - 2s 16ms/step - loss: 0.2863 - accuracy: 0.9059 - val_loss: 0.4559 - val_accuracy: 0.8656\n",
      "Epoch 49/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.3057 - accuracy: 0.8957 - val_loss: 0.5111 - val_accuracy: 0.8488\n",
      "Epoch 50/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 0.2879 - accuracy: 0.9033 - val_loss: 0.4534 - val_accuracy: 0.8660\n",
      "Epoch 51/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 0.2551 - accuracy: 0.9185 - val_loss: 0.4409 - val_accuracy: 0.8692\n",
      "Epoch 52/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 0.2448 - accuracy: 0.9194 - val_loss: 0.5019 - val_accuracy: 0.8556\n",
      "Epoch 53/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.2621 - accuracy: 0.9158 - val_loss: 0.4493 - val_accuracy: 0.8668\n",
      "Epoch 54/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.2427 - accuracy: 0.9193 - val_loss: 0.4246 - val_accuracy: 0.8744\n",
      "Epoch 55/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 0.2200 - accuracy: 0.9292 - val_loss: 0.4403 - val_accuracy: 0.8688\n",
      "Epoch 56/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.2220 - accuracy: 0.9262 - val_loss: 0.4199 - val_accuracy: 0.8788\n",
      "Epoch 57/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.2181 - accuracy: 0.9279 - val_loss: 0.4128 - val_accuracy: 0.8784\n",
      "Epoch 58/1000\n",
      "137/137 [==============================] - 2s 13ms/step - loss: 0.2107 - accuracy: 0.9297 - val_loss: 0.3532 - val_accuracy: 0.9040\n",
      "Epoch 59/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 0.1751 - accuracy: 0.9458 - val_loss: 0.4794 - val_accuracy: 0.8624\n",
      "Epoch 60/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 0.1966 - accuracy: 0.9346 - val_loss: 0.4270 - val_accuracy: 0.8684\n",
      "Epoch 61/1000\n",
      "137/137 [==============================] - 2s 16ms/step - loss: 0.2070 - accuracy: 0.9313 - val_loss: 0.4068 - val_accuracy: 0.8832\n",
      "Epoch 62/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 0.1831 - accuracy: 0.9389 - val_loss: 0.3718 - val_accuracy: 0.8992\n",
      "Epoch 63/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.1722 - accuracy: 0.9425 - val_loss: 0.4320 - val_accuracy: 0.8836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model_t/vgg/250/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model_t/vgg/250/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version =  2.9.1\n",
      "keras version =  2.9.0\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_13 (Conv2D)          (None, 48, 48, 8)         80        \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 48, 48, 8)         584       \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 24, 24, 8)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 24, 24, 16)        1168      \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 24, 24, 16)        2320      \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 12, 12, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 12, 12, 32)        4640      \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 12, 12, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 12, 12, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 6, 6, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 6, 6, 64)          18496     \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, 6, 6, 64)          36928     \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 6, 6, 64)          36928     \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 3, 3, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 3, 3, 64)          36928     \n",
      "                                                                 \n",
      " conv2d_24 (Conv2D)          (None, 3, 3, 64)          36928     \n",
      "                                                                 \n",
      " conv2d_25 (Conv2D)          (None, 3, 3, 64)          36928     \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 1, 1, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 256)               16640     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 25)                3225      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 283,185\n",
      "Trainable params: 283,185\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "137/137 [==============================] - 3s 16ms/step - loss: 3.1671 - accuracy: 0.0543 - val_loss: 2.7935 - val_accuracy: 0.1028\n",
      "Epoch 2/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 2.4590 - accuracy: 0.2092 - val_loss: 2.0692 - val_accuracy: 0.3140\n",
      "Epoch 3/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 1.8948 - accuracy: 0.3657 - val_loss: 1.7722 - val_accuracy: 0.4060\n",
      "Epoch 4/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 1.6884 - accuracy: 0.4375 - val_loss: 1.6388 - val_accuracy: 0.4592\n",
      "Epoch 5/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 1.5640 - accuracy: 0.4806 - val_loss: 1.5238 - val_accuracy: 0.4944\n",
      "Epoch 6/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 1.4930 - accuracy: 0.4973 - val_loss: 1.4820 - val_accuracy: 0.5068\n",
      "Epoch 7/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 1.4168 - accuracy: 0.5238 - val_loss: 1.4175 - val_accuracy: 0.5272\n",
      "Epoch 8/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 1.3677 - accuracy: 0.5376 - val_loss: 1.3884 - val_accuracy: 0.5296\n",
      "Epoch 9/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 1.3047 - accuracy: 0.5623 - val_loss: 1.3745 - val_accuracy: 0.5416\n",
      "Epoch 10/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 1.2776 - accuracy: 0.5702 - val_loss: 1.3650 - val_accuracy: 0.5264\n",
      "Epoch 11/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 1.2278 - accuracy: 0.5892 - val_loss: 1.2966 - val_accuracy: 0.5532\n",
      "Epoch 12/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 1.1880 - accuracy: 0.5965 - val_loss: 1.2437 - val_accuracy: 0.5868\n",
      "Epoch 13/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 1.1593 - accuracy: 0.6059 - val_loss: 1.2201 - val_accuracy: 0.5820\n",
      "Epoch 14/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 1.1169 - accuracy: 0.6235 - val_loss: 1.2146 - val_accuracy: 0.5828\n",
      "Epoch 15/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 1.0761 - accuracy: 0.6342 - val_loss: 1.1293 - val_accuracy: 0.6168\n",
      "Epoch 16/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 1.0465 - accuracy: 0.6461 - val_loss: 1.1575 - val_accuracy: 0.6128\n",
      "Epoch 17/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 1.0120 - accuracy: 0.6601 - val_loss: 1.1260 - val_accuracy: 0.6236\n",
      "Epoch 18/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.9654 - accuracy: 0.6726 - val_loss: 1.1084 - val_accuracy: 0.6288\n",
      "Epoch 19/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 0.9463 - accuracy: 0.6805 - val_loss: 0.9904 - val_accuracy: 0.6696\n",
      "Epoch 20/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 0.8927 - accuracy: 0.6994 - val_loss: 0.9932 - val_accuracy: 0.6592\n",
      "Epoch 21/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.8689 - accuracy: 0.7083 - val_loss: 0.9586 - val_accuracy: 0.6772\n",
      "Epoch 22/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.8318 - accuracy: 0.7198 - val_loss: 0.9517 - val_accuracy: 0.6824\n",
      "Epoch 23/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.7938 - accuracy: 0.7335 - val_loss: 0.9828 - val_accuracy: 0.6732\n",
      "Epoch 24/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.7681 - accuracy: 0.7442 - val_loss: 0.8482 - val_accuracy: 0.7324\n",
      "Epoch 25/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.7368 - accuracy: 0.7545 - val_loss: 0.8697 - val_accuracy: 0.7032\n",
      "Epoch 26/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.7046 - accuracy: 0.7637 - val_loss: 0.7997 - val_accuracy: 0.7380\n",
      "Epoch 27/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 0.6881 - accuracy: 0.7689 - val_loss: 0.7899 - val_accuracy: 0.7324\n",
      "Epoch 28/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 0.6456 - accuracy: 0.7841 - val_loss: 0.7412 - val_accuracy: 0.7584\n",
      "Epoch 29/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.6366 - accuracy: 0.7889 - val_loss: 0.7274 - val_accuracy: 0.7672\n",
      "Epoch 30/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.6046 - accuracy: 0.7985 - val_loss: 0.7528 - val_accuracy: 0.7560\n",
      "Epoch 31/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.5948 - accuracy: 0.8030 - val_loss: 0.6939 - val_accuracy: 0.7684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.5630 - accuracy: 0.8160 - val_loss: 0.6865 - val_accuracy: 0.7796\n",
      "Epoch 33/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 0.5112 - accuracy: 0.8305 - val_loss: 0.6418 - val_accuracy: 0.7992\n",
      "Epoch 34/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 0.5102 - accuracy: 0.8326 - val_loss: 0.6372 - val_accuracy: 0.7964\n",
      "Epoch 35/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.4851 - accuracy: 0.8407 - val_loss: 0.6224 - val_accuracy: 0.7996\n",
      "Epoch 36/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.4774 - accuracy: 0.8418 - val_loss: 0.6154 - val_accuracy: 0.8096\n",
      "Epoch 37/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 0.4880 - accuracy: 0.8346 - val_loss: 0.6166 - val_accuracy: 0.8060\n",
      "Epoch 38/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.4434 - accuracy: 0.8546 - val_loss: 0.5765 - val_accuracy: 0.8128\n",
      "Epoch 39/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.4063 - accuracy: 0.8699 - val_loss: 0.5743 - val_accuracy: 0.8204\n",
      "Epoch 40/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 0.4275 - accuracy: 0.8604 - val_loss: 0.5521 - val_accuracy: 0.8312\n",
      "Epoch 41/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 0.3858 - accuracy: 0.8766 - val_loss: 0.5559 - val_accuracy: 0.8224\n",
      "Epoch 42/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 0.3697 - accuracy: 0.8802 - val_loss: 0.5435 - val_accuracy: 0.8272\n",
      "Epoch 43/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.3851 - accuracy: 0.8723 - val_loss: 0.5560 - val_accuracy: 0.8268\n",
      "Epoch 44/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.3408 - accuracy: 0.8895 - val_loss: 0.5324 - val_accuracy: 0.8340\n",
      "Epoch 45/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.3454 - accuracy: 0.8892 - val_loss: 0.5182 - val_accuracy: 0.8404\n",
      "Epoch 46/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.3258 - accuracy: 0.8953 - val_loss: 0.5651 - val_accuracy: 0.8188\n",
      "Epoch 47/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.3104 - accuracy: 0.8997 - val_loss: 0.5127 - val_accuracy: 0.8400\n",
      "Epoch 48/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.2843 - accuracy: 0.9090 - val_loss: 0.4385 - val_accuracy: 0.8712\n",
      "Epoch 49/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.2889 - accuracy: 0.9070 - val_loss: 0.5623 - val_accuracy: 0.8240\n",
      "Epoch 50/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.2747 - accuracy: 0.9107 - val_loss: 0.4291 - val_accuracy: 0.8680\n",
      "Epoch 51/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.2573 - accuracy: 0.9193 - val_loss: 0.4335 - val_accuracy: 0.8688\n",
      "Epoch 52/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.2628 - accuracy: 0.9145 - val_loss: 0.4462 - val_accuracy: 0.8648\n",
      "Epoch 53/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.2704 - accuracy: 0.9113 - val_loss: 0.4470 - val_accuracy: 0.8668\n",
      "Epoch 54/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 0.2399 - accuracy: 0.9224 - val_loss: 0.4372 - val_accuracy: 0.8712\n",
      "Epoch 55/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 0.2303 - accuracy: 0.9277 - val_loss: 0.4685 - val_accuracy: 0.8580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model_t/vgg/251/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model_t/vgg/251/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version =  2.9.1\n",
      "keras version =  2.9.0\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_26 (Conv2D)          (None, 48, 48, 8)         80        \n",
      "                                                                 \n",
      " conv2d_27 (Conv2D)          (None, 48, 48, 8)         584       \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 24, 24, 8)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_28 (Conv2D)          (None, 24, 24, 16)        1168      \n",
      "                                                                 \n",
      " conv2d_29 (Conv2D)          (None, 24, 24, 16)        2320      \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 12, 12, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_30 (Conv2D)          (None, 12, 12, 32)        4640      \n",
      "                                                                 \n",
      " conv2d_31 (Conv2D)          (None, 12, 12, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_32 (Conv2D)          (None, 12, 12, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPoolin  (None, 6, 6, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_33 (Conv2D)          (None, 6, 6, 64)          18496     \n",
      "                                                                 \n",
      " conv2d_34 (Conv2D)          (None, 6, 6, 64)          36928     \n",
      "                                                                 \n",
      " conv2d_35 (Conv2D)          (None, 6, 6, 64)          36928     \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPoolin  (None, 3, 3, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_36 (Conv2D)          (None, 3, 3, 64)          36928     \n",
      "                                                                 \n",
      " conv2d_37 (Conv2D)          (None, 3, 3, 64)          36928     \n",
      "                                                                 \n",
      " conv2d_38 (Conv2D)          (None, 3, 3, 64)          36928     \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPoolin  (None, 1, 1, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 256)               16640     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 25)                3225      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 283,185\n",
      "Trainable params: 283,185\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "137/137 [==============================] - 3s 17ms/step - loss: 3.1673 - accuracy: 0.0573 - val_loss: 2.7669 - val_accuracy: 0.1188\n",
      "Epoch 2/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 2.3255 - accuracy: 0.2475 - val_loss: 2.0339 - val_accuracy: 0.3072\n",
      "Epoch 3/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 1.8593 - accuracy: 0.3761 - val_loss: 1.7617 - val_accuracy: 0.3920\n",
      "Epoch 4/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 1.7108 - accuracy: 0.4291 - val_loss: 1.6645 - val_accuracy: 0.4420\n",
      "Epoch 5/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 1.5986 - accuracy: 0.4645 - val_loss: 1.5671 - val_accuracy: 0.4756\n",
      "Epoch 6/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 1.5514 - accuracy: 0.4766 - val_loss: 1.5704 - val_accuracy: 0.4676\n",
      "Epoch 7/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 1.4742 - accuracy: 0.5035 - val_loss: 1.4504 - val_accuracy: 0.5036\n",
      "Epoch 8/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 1.4329 - accuracy: 0.5143 - val_loss: 1.4856 - val_accuracy: 0.4840\n",
      "Epoch 9/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 1.3770 - accuracy: 0.5302 - val_loss: 1.4749 - val_accuracy: 0.4992\n",
      "Epoch 10/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 1.3446 - accuracy: 0.5403 - val_loss: 1.3990 - val_accuracy: 0.5204\n",
      "Epoch 11/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 1.2872 - accuracy: 0.5633 - val_loss: 1.3901 - val_accuracy: 0.5200\n",
      "Epoch 12/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 1.2474 - accuracy: 0.5730 - val_loss: 1.2691 - val_accuracy: 0.5700\n",
      "Epoch 13/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 1.2204 - accuracy: 0.5813 - val_loss: 1.2786 - val_accuracy: 0.5672\n",
      "Epoch 14/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 1.1757 - accuracy: 0.5998 - val_loss: 1.2545 - val_accuracy: 0.5724\n",
      "Epoch 15/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 1.1418 - accuracy: 0.6111 - val_loss: 1.1972 - val_accuracy: 0.5888\n",
      "Epoch 16/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 1.1036 - accuracy: 0.6271 - val_loss: 1.1897 - val_accuracy: 0.5976\n",
      "Epoch 17/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 1.0830 - accuracy: 0.6296 - val_loss: 1.1467 - val_accuracy: 0.6088\n",
      "Epoch 18/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 1.0294 - accuracy: 0.6509 - val_loss: 1.1138 - val_accuracy: 0.6148\n",
      "Epoch 19/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 1.0088 - accuracy: 0.6582 - val_loss: 1.1031 - val_accuracy: 0.6164\n",
      "Epoch 20/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.9618 - accuracy: 0.6778 - val_loss: 1.0523 - val_accuracy: 0.6444\n",
      "Epoch 21/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.9311 - accuracy: 0.6874 - val_loss: 0.9935 - val_accuracy: 0.6600\n",
      "Epoch 22/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 0.8907 - accuracy: 0.6986 - val_loss: 0.9918 - val_accuracy: 0.6684\n",
      "Epoch 23/1000\n",
      "137/137 [==============================] - 2s 13ms/step - loss: 0.8719 - accuracy: 0.7071 - val_loss: 1.0061 - val_accuracy: 0.6628\n",
      "Epoch 24/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 0.8134 - accuracy: 0.7242 - val_loss: 0.9111 - val_accuracy: 0.6972\n",
      "Epoch 25/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.7800 - accuracy: 0.7375 - val_loss: 0.9172 - val_accuracy: 0.6872\n",
      "Epoch 26/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.7580 - accuracy: 0.7449 - val_loss: 0.8415 - val_accuracy: 0.7252\n",
      "Epoch 27/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.7309 - accuracy: 0.7546 - val_loss: 0.8420 - val_accuracy: 0.7216\n",
      "Epoch 28/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.6832 - accuracy: 0.7720 - val_loss: 0.7762 - val_accuracy: 0.7468\n",
      "Epoch 29/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.6555 - accuracy: 0.7820 - val_loss: 0.7799 - val_accuracy: 0.7420\n",
      "Epoch 30/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.6292 - accuracy: 0.7923 - val_loss: 0.7393 - val_accuracy: 0.7612\n",
      "Epoch 31/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.6248 - accuracy: 0.7903 - val_loss: 0.8658 - val_accuracy: 0.7184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.5926 - accuracy: 0.8001 - val_loss: 0.6752 - val_accuracy: 0.7828\n",
      "Epoch 33/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.5332 - accuracy: 0.8208 - val_loss: 0.6700 - val_accuracy: 0.7888\n",
      "Epoch 34/1000\n",
      "137/137 [==============================] - 2s 16ms/step - loss: 0.5372 - accuracy: 0.8198 - val_loss: 0.6487 - val_accuracy: 0.7972\n",
      "Epoch 35/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 0.5122 - accuracy: 0.8303 - val_loss: 0.6867 - val_accuracy: 0.7760\n",
      "Epoch 36/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 0.4968 - accuracy: 0.8353 - val_loss: 0.5891 - val_accuracy: 0.8152\n",
      "Epoch 37/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 0.4858 - accuracy: 0.8347 - val_loss: 0.6187 - val_accuracy: 0.8036\n",
      "Epoch 38/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 0.4430 - accuracy: 0.8534 - val_loss: 0.6150 - val_accuracy: 0.8032\n",
      "Epoch 39/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.4380 - accuracy: 0.8540 - val_loss: 0.6509 - val_accuracy: 0.7860\n",
      "Epoch 40/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.4237 - accuracy: 0.8601 - val_loss: 0.5837 - val_accuracy: 0.8188\n",
      "Epoch 41/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.3963 - accuracy: 0.8688 - val_loss: 0.5483 - val_accuracy: 0.8276\n",
      "Epoch 42/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 0.3784 - accuracy: 0.8747 - val_loss: 0.5376 - val_accuracy: 0.8312\n",
      "Epoch 43/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.3703 - accuracy: 0.8776 - val_loss: 0.5119 - val_accuracy: 0.8396\n",
      "Epoch 44/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.3470 - accuracy: 0.8851 - val_loss: 0.6021 - val_accuracy: 0.8084\n",
      "Epoch 45/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.3470 - accuracy: 0.8871 - val_loss: 0.4973 - val_accuracy: 0.8516\n",
      "Epoch 46/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.3281 - accuracy: 0.8947 - val_loss: 0.5737 - val_accuracy: 0.8184\n",
      "Epoch 47/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.3170 - accuracy: 0.8961 - val_loss: 0.4578 - val_accuracy: 0.8580\n",
      "Epoch 48/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.2834 - accuracy: 0.9086 - val_loss: 0.4600 - val_accuracy: 0.8568\n",
      "Epoch 49/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.3022 - accuracy: 0.8983 - val_loss: 0.5727 - val_accuracy: 0.8164\n",
      "Epoch 50/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.2872 - accuracy: 0.9053 - val_loss: 0.4799 - val_accuracy: 0.8508\n",
      "Epoch 51/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 0.2553 - accuracy: 0.9185 - val_loss: 0.4390 - val_accuracy: 0.8768\n",
      "Epoch 52/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.2917 - accuracy: 0.9045 - val_loss: 0.4138 - val_accuracy: 0.8724\n",
      "Epoch 53/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.2534 - accuracy: 0.9171 - val_loss: 0.4281 - val_accuracy: 0.8676\n",
      "Epoch 54/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.2338 - accuracy: 0.9238 - val_loss: 0.4312 - val_accuracy: 0.8644\n",
      "Epoch 55/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.2139 - accuracy: 0.9306 - val_loss: 0.4267 - val_accuracy: 0.8764\n",
      "Epoch 56/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.2137 - accuracy: 0.9298 - val_loss: 0.3912 - val_accuracy: 0.8832\n",
      "Epoch 57/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.2165 - accuracy: 0.9295 - val_loss: 0.4308 - val_accuracy: 0.8748\n",
      "Epoch 58/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.2201 - accuracy: 0.9275 - val_loss: 0.3642 - val_accuracy: 0.8932\n",
      "Epoch 59/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 0.1917 - accuracy: 0.9389 - val_loss: 0.4717 - val_accuracy: 0.8656\n",
      "Epoch 60/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 0.2070 - accuracy: 0.9325 - val_loss: 0.3911 - val_accuracy: 0.8848\n",
      "Epoch 61/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.1857 - accuracy: 0.9403 - val_loss: 0.3513 - val_accuracy: 0.9040\n",
      "Epoch 62/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 0.1883 - accuracy: 0.9369 - val_loss: 0.3812 - val_accuracy: 0.8904\n",
      "Epoch 63/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.1665 - accuracy: 0.9467 - val_loss: 0.3866 - val_accuracy: 0.8900\n",
      "Epoch 64/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 0.1728 - accuracy: 0.9428 - val_loss: 0.3669 - val_accuracy: 0.8924\n",
      "Epoch 65/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.1642 - accuracy: 0.9478 - val_loss: 0.3526 - val_accuracy: 0.9004\n",
      "Epoch 66/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.1533 - accuracy: 0.9509 - val_loss: 0.3440 - val_accuracy: 0.9076\n",
      "Epoch 67/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.1469 - accuracy: 0.9515 - val_loss: 0.3824 - val_accuracy: 0.8948\n",
      "Epoch 68/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.1523 - accuracy: 0.9479 - val_loss: 0.3210 - val_accuracy: 0.9144\n",
      "Epoch 69/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.1414 - accuracy: 0.9549 - val_loss: 0.3406 - val_accuracy: 0.9052\n",
      "Epoch 70/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.1542 - accuracy: 0.9493 - val_loss: 0.3219 - val_accuracy: 0.9096\n",
      "Epoch 71/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.1328 - accuracy: 0.9569 - val_loss: 0.3738 - val_accuracy: 0.8984\n",
      "Epoch 72/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.1229 - accuracy: 0.9597 - val_loss: 0.3279 - val_accuracy: 0.9140\n",
      "Epoch 73/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.1103 - accuracy: 0.9651 - val_loss: 0.3398 - val_accuracy: 0.9120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model_t/vgg/252/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model_t/vgg/252/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version =  2.9.1\n",
      "keras version =  2.9.0\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_39 (Conv2D)          (None, 48, 48, 8)         80        \n",
      "                                                                 \n",
      " conv2d_40 (Conv2D)          (None, 48, 48, 8)         584       \n",
      "                                                                 \n",
      " max_pooling2d_15 (MaxPoolin  (None, 24, 24, 8)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_41 (Conv2D)          (None, 24, 24, 16)        1168      \n",
      "                                                                 \n",
      " conv2d_42 (Conv2D)          (None, 24, 24, 16)        2320      \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPoolin  (None, 12, 12, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_43 (Conv2D)          (None, 12, 12, 32)        4640      \n",
      "                                                                 \n",
      " conv2d_44 (Conv2D)          (None, 12, 12, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_45 (Conv2D)          (None, 12, 12, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPoolin  (None, 6, 6, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_46 (Conv2D)          (None, 6, 6, 64)          18496     \n",
      "                                                                 \n",
      " conv2d_47 (Conv2D)          (None, 6, 6, 64)          36928     \n",
      "                                                                 \n",
      " conv2d_48 (Conv2D)          (None, 6, 6, 64)          36928     \n",
      "                                                                 \n",
      " max_pooling2d_18 (MaxPoolin  (None, 3, 3, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_49 (Conv2D)          (None, 3, 3, 64)          36928     \n",
      "                                                                 \n",
      " conv2d_50 (Conv2D)          (None, 3, 3, 64)          36928     \n",
      "                                                                 \n",
      " conv2d_51 (Conv2D)          (None, 3, 3, 64)          36928     \n",
      "                                                                 \n",
      " max_pooling2d_19 (MaxPoolin  (None, 1, 1, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 256)               16640     \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 25)                3225      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 283,185\n",
      "Trainable params: 283,185\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "137/137 [==============================] - 3s 16ms/step - loss: 3.1821 - accuracy: 0.0498 - val_loss: 2.8356 - val_accuracy: 0.1152\n",
      "Epoch 2/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 2.3617 - accuracy: 0.2435 - val_loss: 2.0770 - val_accuracy: 0.3044\n",
      "Epoch 3/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 1.8793 - accuracy: 0.3730 - val_loss: 1.7715 - val_accuracy: 0.4084\n",
      "Epoch 4/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 1.7106 - accuracy: 0.4283 - val_loss: 1.6573 - val_accuracy: 0.4500\n",
      "Epoch 5/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 1.5933 - accuracy: 0.4689 - val_loss: 1.5706 - val_accuracy: 0.4724\n",
      "Epoch 6/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 1.5346 - accuracy: 0.4861 - val_loss: 1.5433 - val_accuracy: 0.4768\n",
      "Epoch 7/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 1.4583 - accuracy: 0.5126 - val_loss: 1.4646 - val_accuracy: 0.5044\n",
      "Epoch 8/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 1.4157 - accuracy: 0.5221 - val_loss: 1.4268 - val_accuracy: 0.5028\n",
      "Epoch 9/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 1.3586 - accuracy: 0.5427 - val_loss: 1.4402 - val_accuracy: 0.5224\n",
      "Epoch 10/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 1.3168 - accuracy: 0.5536 - val_loss: 1.3769 - val_accuracy: 0.5328\n",
      "Epoch 11/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 1.2632 - accuracy: 0.5743 - val_loss: 1.3302 - val_accuracy: 0.5348\n",
      "Epoch 12/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 1.2255 - accuracy: 0.5818 - val_loss: 1.2440 - val_accuracy: 0.5848\n",
      "Epoch 13/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 1.2034 - accuracy: 0.5917 - val_loss: 1.2516 - val_accuracy: 0.5724\n",
      "Epoch 14/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 1.1587 - accuracy: 0.6082 - val_loss: 1.2469 - val_accuracy: 0.5808\n",
      "Epoch 15/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 1.1162 - accuracy: 0.6226 - val_loss: 1.1736 - val_accuracy: 0.5960\n",
      "Epoch 16/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 1.0851 - accuracy: 0.6301 - val_loss: 1.1739 - val_accuracy: 0.6104\n",
      "Epoch 17/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 1.0605 - accuracy: 0.6387 - val_loss: 1.1434 - val_accuracy: 0.6024\n",
      "Epoch 18/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 1.0066 - accuracy: 0.6606 - val_loss: 1.1250 - val_accuracy: 0.6260\n",
      "Epoch 19/1000\n",
      "137/137 [==============================] - 2s 13ms/step - loss: 0.9817 - accuracy: 0.6673 - val_loss: 1.0413 - val_accuracy: 0.6460\n",
      "Epoch 20/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.9353 - accuracy: 0.6846 - val_loss: 1.0279 - val_accuracy: 0.6584\n",
      "Epoch 21/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.9045 - accuracy: 0.6978 - val_loss: 0.9919 - val_accuracy: 0.6680\n",
      "Epoch 22/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 0.8711 - accuracy: 0.7075 - val_loss: 0.9603 - val_accuracy: 0.6788\n",
      "Epoch 23/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.8330 - accuracy: 0.7197 - val_loss: 0.9951 - val_accuracy: 0.6516\n",
      "Epoch 24/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 0.8002 - accuracy: 0.7322 - val_loss: 0.8747 - val_accuracy: 0.7176\n",
      "Epoch 25/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 0.7414 - accuracy: 0.7551 - val_loss: 0.8299 - val_accuracy: 0.7276\n",
      "Epoch 26/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 0.7179 - accuracy: 0.7619 - val_loss: 0.8822 - val_accuracy: 0.7100\n",
      "Epoch 27/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 0.7081 - accuracy: 0.7619 - val_loss: 0.8121 - val_accuracy: 0.7300\n",
      "Epoch 28/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 0.6592 - accuracy: 0.7806 - val_loss: 0.7986 - val_accuracy: 0.7396\n",
      "Epoch 29/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 0.6326 - accuracy: 0.7903 - val_loss: 0.7259 - val_accuracy: 0.7624\n",
      "Epoch 30/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 0.5979 - accuracy: 0.8002 - val_loss: 0.7642 - val_accuracy: 0.7512\n",
      "Epoch 31/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 0.6063 - accuracy: 0.8004 - val_loss: 0.6777 - val_accuracy: 0.7808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 0.5617 - accuracy: 0.8127 - val_loss: 0.6837 - val_accuracy: 0.7744\n",
      "Epoch 33/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 0.5263 - accuracy: 0.8236 - val_loss: 0.6858 - val_accuracy: 0.7752\n",
      "Epoch 34/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 0.4974 - accuracy: 0.8366 - val_loss: 0.6043 - val_accuracy: 0.8020\n",
      "Epoch 35/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 0.4844 - accuracy: 0.8403 - val_loss: 0.6375 - val_accuracy: 0.7980\n",
      "Epoch 36/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 0.4731 - accuracy: 0.8426 - val_loss: 0.5928 - val_accuracy: 0.8220\n",
      "Epoch 37/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 0.4836 - accuracy: 0.8394 - val_loss: 0.5971 - val_accuracy: 0.8056\n",
      "Epoch 38/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 0.4410 - accuracy: 0.8525 - val_loss: 0.5775 - val_accuracy: 0.8200\n",
      "Epoch 39/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 0.4154 - accuracy: 0.8642 - val_loss: 0.6110 - val_accuracy: 0.7996\n",
      "Epoch 40/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.4201 - accuracy: 0.8623 - val_loss: 0.5955 - val_accuracy: 0.8048\n",
      "Epoch 41/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.3883 - accuracy: 0.8726 - val_loss: 0.5542 - val_accuracy: 0.8216\n",
      "Epoch 42/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.3732 - accuracy: 0.8761 - val_loss: 0.5148 - val_accuracy: 0.8344\n",
      "Epoch 43/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 0.3699 - accuracy: 0.8791 - val_loss: 0.4809 - val_accuracy: 0.8488\n",
      "Epoch 44/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 0.3597 - accuracy: 0.8814 - val_loss: 0.6782 - val_accuracy: 0.7848\n",
      "Epoch 45/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 0.3417 - accuracy: 0.8884 - val_loss: 0.4731 - val_accuracy: 0.8416\n",
      "Epoch 46/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 0.3306 - accuracy: 0.8913 - val_loss: 0.5744 - val_accuracy: 0.8128\n",
      "Epoch 47/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.3263 - accuracy: 0.8923 - val_loss: 0.4578 - val_accuracy: 0.8564\n",
      "Epoch 48/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.2844 - accuracy: 0.9094 - val_loss: 0.4491 - val_accuracy: 0.8580\n",
      "Epoch 49/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 0.2892 - accuracy: 0.9048 - val_loss: 0.4776 - val_accuracy: 0.8476\n",
      "Epoch 50/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.2902 - accuracy: 0.9032 - val_loss: 0.4895 - val_accuracy: 0.8552\n",
      "Epoch 51/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.2670 - accuracy: 0.9149 - val_loss: 0.4540 - val_accuracy: 0.8536\n",
      "Epoch 52/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 0.2633 - accuracy: 0.9125 - val_loss: 0.4768 - val_accuracy: 0.8544\n",
      "Epoch 53/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.2646 - accuracy: 0.9137 - val_loss: 0.4367 - val_accuracy: 0.8672\n",
      "Epoch 54/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.2515 - accuracy: 0.9162 - val_loss: 0.4358 - val_accuracy: 0.8692\n",
      "Epoch 55/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.2236 - accuracy: 0.9278 - val_loss: 0.3923 - val_accuracy: 0.8860\n",
      "Epoch 56/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 0.2216 - accuracy: 0.9273 - val_loss: 0.4547 - val_accuracy: 0.8668\n",
      "Epoch 57/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.2289 - accuracy: 0.9234 - val_loss: 0.4081 - val_accuracy: 0.8760\n",
      "Epoch 58/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.2237 - accuracy: 0.9254 - val_loss: 0.3928 - val_accuracy: 0.8812\n",
      "Epoch 59/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.1944 - accuracy: 0.9362 - val_loss: 0.4011 - val_accuracy: 0.8808\n",
      "Epoch 60/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.1951 - accuracy: 0.9378 - val_loss: 0.3912 - val_accuracy: 0.8852\n",
      "Epoch 61/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.2011 - accuracy: 0.9329 - val_loss: 0.4129 - val_accuracy: 0.8796\n",
      "Epoch 62/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 0.1940 - accuracy: 0.9374 - val_loss: 0.3337 - val_accuracy: 0.9052\n",
      "Epoch 63/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.1921 - accuracy: 0.9370 - val_loss: 0.3834 - val_accuracy: 0.8840\n",
      "Epoch 64/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 0.1773 - accuracy: 0.9399 - val_loss: 0.3874 - val_accuracy: 0.8872\n",
      "Epoch 65/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.1816 - accuracy: 0.9423 - val_loss: 0.3531 - val_accuracy: 0.8976\n",
      "Epoch 66/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.1602 - accuracy: 0.9476 - val_loss: 0.3603 - val_accuracy: 0.8992\n",
      "Epoch 67/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 0.1582 - accuracy: 0.9486 - val_loss: 0.3348 - val_accuracy: 0.9084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model_t/vgg/253/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model_t/vgg/253/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version =  2.9.1\n",
      "keras version =  2.9.0\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_52 (Conv2D)          (None, 48, 48, 8)         80        \n",
      "                                                                 \n",
      " conv2d_53 (Conv2D)          (None, 48, 48, 8)         584       \n",
      "                                                                 \n",
      " max_pooling2d_20 (MaxPoolin  (None, 24, 24, 8)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_54 (Conv2D)          (None, 24, 24, 16)        1168      \n",
      "                                                                 \n",
      " conv2d_55 (Conv2D)          (None, 24, 24, 16)        2320      \n",
      "                                                                 \n",
      " max_pooling2d_21 (MaxPoolin  (None, 12, 12, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_56 (Conv2D)          (None, 12, 12, 32)        4640      \n",
      "                                                                 \n",
      " conv2d_57 (Conv2D)          (None, 12, 12, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_58 (Conv2D)          (None, 12, 12, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_22 (MaxPoolin  (None, 6, 6, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_59 (Conv2D)          (None, 6, 6, 64)          18496     \n",
      "                                                                 \n",
      " conv2d_60 (Conv2D)          (None, 6, 6, 64)          36928     \n",
      "                                                                 \n",
      " conv2d_61 (Conv2D)          (None, 6, 6, 64)          36928     \n",
      "                                                                 \n",
      " max_pooling2d_23 (MaxPoolin  (None, 3, 3, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_62 (Conv2D)          (None, 3, 3, 64)          36928     \n",
      "                                                                 \n",
      " conv2d_63 (Conv2D)          (None, 3, 3, 64)          36928     \n",
      "                                                                 \n",
      " conv2d_64 (Conv2D)          (None, 3, 3, 64)          36928     \n",
      "                                                                 \n",
      " max_pooling2d_24 (MaxPoolin  (None, 1, 1, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 256)               16640     \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 25)                3225      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 283,185\n",
      "Trainable params: 283,185\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "137/137 [==============================] - 3s 16ms/step - loss: 3.1615 - accuracy: 0.0548 - val_loss: 2.7830 - val_accuracy: 0.1140\n",
      "Epoch 2/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 2.3974 - accuracy: 0.2172 - val_loss: 2.0098 - val_accuracy: 0.3292\n",
      "Epoch 3/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 1.8858 - accuracy: 0.3603 - val_loss: 1.7947 - val_accuracy: 0.3908\n",
      "Epoch 4/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 1.7247 - accuracy: 0.4194 - val_loss: 1.6663 - val_accuracy: 0.4488\n",
      "Epoch 5/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 1.6033 - accuracy: 0.4650 - val_loss: 1.5867 - val_accuracy: 0.4676\n",
      "Epoch 6/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 1.5355 - accuracy: 0.4841 - val_loss: 1.5242 - val_accuracy: 0.4908\n",
      "Epoch 7/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 1.4580 - accuracy: 0.5086 - val_loss: 1.4480 - val_accuracy: 0.5020\n",
      "Epoch 8/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 1.4113 - accuracy: 0.5239 - val_loss: 1.4296 - val_accuracy: 0.5164\n",
      "Epoch 9/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 1.3454 - accuracy: 0.5465 - val_loss: 1.3720 - val_accuracy: 0.5456\n",
      "Epoch 10/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 1.3151 - accuracy: 0.5531 - val_loss: 1.3816 - val_accuracy: 0.5268\n",
      "Epoch 11/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 1.2531 - accuracy: 0.5752 - val_loss: 1.3192 - val_accuracy: 0.5312\n",
      "Epoch 12/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 1.2145 - accuracy: 0.5844 - val_loss: 1.2629 - val_accuracy: 0.5740\n",
      "Epoch 13/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 1.1932 - accuracy: 0.5914 - val_loss: 1.2211 - val_accuracy: 0.5776\n",
      "Epoch 14/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 1.1342 - accuracy: 0.6135 - val_loss: 1.1852 - val_accuracy: 0.5932\n",
      "Epoch 15/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 1.1017 - accuracy: 0.6237 - val_loss: 1.1818 - val_accuracy: 0.5932\n",
      "Epoch 16/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 1.0644 - accuracy: 0.6405 - val_loss: 1.1400 - val_accuracy: 0.6116\n",
      "Epoch 17/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 1.0353 - accuracy: 0.6459 - val_loss: 1.1851 - val_accuracy: 0.6024\n",
      "Epoch 18/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.9986 - accuracy: 0.6621 - val_loss: 1.0698 - val_accuracy: 0.6320\n",
      "Epoch 19/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.9721 - accuracy: 0.6666 - val_loss: 1.0265 - val_accuracy: 0.6476\n",
      "Epoch 20/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.9243 - accuracy: 0.6863 - val_loss: 0.9966 - val_accuracy: 0.6596\n",
      "Epoch 21/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.8996 - accuracy: 0.6951 - val_loss: 0.9646 - val_accuracy: 0.6712\n",
      "Epoch 22/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.8602 - accuracy: 0.7094 - val_loss: 0.9191 - val_accuracy: 0.6880\n",
      "Epoch 23/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 0.8468 - accuracy: 0.7142 - val_loss: 0.9353 - val_accuracy: 0.6824\n",
      "Epoch 24/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.7938 - accuracy: 0.7321 - val_loss: 0.8623 - val_accuracy: 0.7208\n",
      "Epoch 25/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.7580 - accuracy: 0.7445 - val_loss: 0.8503 - val_accuracy: 0.7136\n",
      "Epoch 26/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.7351 - accuracy: 0.7546 - val_loss: 0.8093 - val_accuracy: 0.7284\n",
      "Epoch 27/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.7096 - accuracy: 0.7617 - val_loss: 0.8221 - val_accuracy: 0.7156\n",
      "Epoch 28/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.6745 - accuracy: 0.7742 - val_loss: 0.7858 - val_accuracy: 0.7332\n",
      "Epoch 29/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.6393 - accuracy: 0.7876 - val_loss: 0.7086 - val_accuracy: 0.7636\n",
      "Epoch 30/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.5924 - accuracy: 0.8053 - val_loss: 0.7030 - val_accuracy: 0.7624\n",
      "Epoch 31/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.5918 - accuracy: 0.8039 - val_loss: 0.6601 - val_accuracy: 0.7700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.5519 - accuracy: 0.8176 - val_loss: 0.6128 - val_accuracy: 0.8056\n",
      "Epoch 33/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.5044 - accuracy: 0.8341 - val_loss: 0.5899 - val_accuracy: 0.8004\n",
      "Epoch 34/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.5011 - accuracy: 0.8333 - val_loss: 0.5768 - val_accuracy: 0.8080\n",
      "Epoch 35/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.4669 - accuracy: 0.8451 - val_loss: 0.5535 - val_accuracy: 0.8240\n",
      "Epoch 36/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.4561 - accuracy: 0.8462 - val_loss: 0.5546 - val_accuracy: 0.8176\n",
      "Epoch 37/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.4507 - accuracy: 0.8477 - val_loss: 0.5803 - val_accuracy: 0.8120\n",
      "Epoch 38/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.4074 - accuracy: 0.8673 - val_loss: 0.5473 - val_accuracy: 0.8252\n",
      "Epoch 39/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.3824 - accuracy: 0.8770 - val_loss: 0.5601 - val_accuracy: 0.8140\n",
      "Epoch 40/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.3803 - accuracy: 0.8747 - val_loss: 0.5421 - val_accuracy: 0.8264\n",
      "Epoch 41/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.3655 - accuracy: 0.8803 - val_loss: 0.4918 - val_accuracy: 0.8424\n",
      "Epoch 42/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.3363 - accuracy: 0.8913 - val_loss: 0.5087 - val_accuracy: 0.8384\n",
      "Epoch 43/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.3346 - accuracy: 0.8897 - val_loss: 0.4507 - val_accuracy: 0.8512\n",
      "Epoch 44/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 0.2960 - accuracy: 0.9048 - val_loss: 0.4796 - val_accuracy: 0.8432\n",
      "Epoch 45/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.2953 - accuracy: 0.9024 - val_loss: 0.4343 - val_accuracy: 0.8592\n",
      "Epoch 46/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.2907 - accuracy: 0.9068 - val_loss: 0.4497 - val_accuracy: 0.8576\n",
      "Epoch 47/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.2933 - accuracy: 0.9029 - val_loss: 0.3959 - val_accuracy: 0.8724\n",
      "Epoch 48/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.2460 - accuracy: 0.9212 - val_loss: 0.3835 - val_accuracy: 0.8808\n",
      "Epoch 49/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.2673 - accuracy: 0.9122 - val_loss: 0.3733 - val_accuracy: 0.8904\n",
      "Epoch 50/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.2603 - accuracy: 0.9146 - val_loss: 0.3473 - val_accuracy: 0.9004\n",
      "Epoch 51/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 0.2278 - accuracy: 0.9250 - val_loss: 0.3554 - val_accuracy: 0.8900\n",
      "Epoch 52/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 0.2191 - accuracy: 0.9298 - val_loss: 0.4117 - val_accuracy: 0.8780\n",
      "Epoch 53/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.2300 - accuracy: 0.9236 - val_loss: 0.3402 - val_accuracy: 0.8984\n",
      "Epoch 54/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.2011 - accuracy: 0.9354 - val_loss: 0.4134 - val_accuracy: 0.8732\n",
      "Epoch 55/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.2016 - accuracy: 0.9357 - val_loss: 0.3617 - val_accuracy: 0.8900\n",
      "Epoch 56/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.1989 - accuracy: 0.9350 - val_loss: 0.3839 - val_accuracy: 0.8856\n",
      "Epoch 57/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.1975 - accuracy: 0.9355 - val_loss: 0.3812 - val_accuracy: 0.8820\n",
      "Epoch 58/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.1902 - accuracy: 0.9365 - val_loss: 0.3049 - val_accuracy: 0.9084\n",
      "Epoch 59/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.1597 - accuracy: 0.9508 - val_loss: 0.3455 - val_accuracy: 0.8980\n",
      "Epoch 60/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.2056 - accuracy: 0.9315 - val_loss: 0.2915 - val_accuracy: 0.9176\n",
      "Epoch 61/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.1715 - accuracy: 0.9445 - val_loss: 0.3227 - val_accuracy: 0.9048\n",
      "Epoch 62/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.1484 - accuracy: 0.9534 - val_loss: 0.2884 - val_accuracy: 0.9232\n",
      "Epoch 63/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.1478 - accuracy: 0.9546 - val_loss: 0.2909 - val_accuracy: 0.9160\n",
      "Epoch 64/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.1550 - accuracy: 0.9505 - val_loss: 0.3258 - val_accuracy: 0.8992\n",
      "Epoch 65/1000\n",
      "137/137 [==============================] - 2s 14ms/step - loss: 0.1440 - accuracy: 0.9532 - val_loss: 0.3048 - val_accuracy: 0.9084\n",
      "Epoch 66/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.1485 - accuracy: 0.9517 - val_loss: 0.2885 - val_accuracy: 0.9140\n",
      "Epoch 67/1000\n",
      "137/137 [==============================] - 2s 15ms/step - loss: 0.1466 - accuracy: 0.9520 - val_loss: 0.3244 - val_accuracy: 0.8992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model_t/vgg/254/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model_t/vgg/254/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9621142745018005\n",
      "0.9232000112533569\n",
      "0.9039999842643738\n"
     ]
    }
   ],
   "source": [
    "for i in range(25,26):\n",
    "    test_acc=[]\n",
    "    train_acc=[]\n",
    "    valid_acc=[]\n",
    "    for j in range(5):\n",
    "        target_cnt=i\n",
    "        x_train_all, t_train_all, x_validation_all, t_validation_all, x_validation,t_validation,x_train, t_train, x_test, t_test=\\\n",
    "        make_dataset(foot,target,target_cnt,random_state)\n",
    "        #lenet5\n",
    "#         model=lenet5(random_state)\n",
    "        #AlexNet\n",
    "#         model=alexnet(random_state)\n",
    "        #ResNet 18\n",
    "#         model=ResNet18(25)\n",
    "        \n",
    "\n",
    "#         def get_functional_model(model):\n",
    "#             # 이 코드는「이전 포스팅의 Functional API」와 거의 동일\n",
    "#             x = keras.layers.Input(shape=(48,48,1), name='layer_in')\n",
    "#             temp_model = tf.keras.Model(\n",
    "#                 inputs=[x],\n",
    "#                 outputs=model.call(x),  # ※서브 클래스화한 모델의 'call'메소드를 지정\n",
    "#                 name='subclassing_model3')  # 임의의 모델에도 이름을 붙인다.\n",
    "#             return temp_model\n",
    "\n",
    "#         # Functional API의「임의의 모델」을 취득\n",
    "#         f_model = get_functional_model(model)\n",
    "\n",
    "#         # 모델의 내용을 출력\n",
    "#         f_model.summary()\n",
    "#         model.build(input_shape = (None,48,48,1))\n",
    "#         model.compile(optimizer = \"adam\",loss='categorical_crossentropy', metrics=[\"accuracy\"]) \n",
    "        #vgg16\n",
    "        model=VGG16(random_state)\n",
    "        #googlenet\n",
    "#         model=GoogLeNet(random_state)\n",
    "        epoch=1000\n",
    "        batch=128\n",
    "        onehot_encoder = OneHotEncoder()\n",
    "        early_stopping = EarlyStopping(monitor='val_loss',verbose=0,min_delta=0,patience=5,restore_best_weights=True)\n",
    "        o_t_validation=onehot_encoder.fit_transform(t_validation_all).toarray()\n",
    "        o_t_train=onehot_encoder.fit_transform(t_train_all).toarray()\n",
    "        history =model.fit(x_train_all,o_t_train,epochs=epoch, validation_data=(x_validation_all, o_t_validation),batch_size=batch,verbose=1,callbacks=[early_stopping])\n",
    "        o_t_test=onehot_encoder.fit_transform(t_test).toarray()\n",
    "        test_acc.append(model.evaluate(x_test,o_t_test,verbose=0)[1])\n",
    "        train_acc.append(model.evaluate(x_train_all,o_t_train,verbose=0)[1])\n",
    "        valid_acc.append(model.evaluate(x_validation_all,o_t_validation,verbose=0)[1])\n",
    "        createDirectory(\"./model_t/vgg/\"+str(i)+str(j))\n",
    "        model.save(\"./model_t/vgg/\"+str(i)+str(j)+\"/\")\n",
    "    arg=np.argmax(np.array(test_acc))\n",
    "    print(train_acc[arg])\n",
    "    print(valid_acc[arg])\n",
    "    print(test_acc[arg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3b0ac48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path=\"./model/google/\"+str(25)+str(0)+\"/\"\n",
    "newmodel=tf.keras.models.load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "749216e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Model(newmodel.input,newmodel.output[0])\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.Adam(),\n",
    "                  metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ccd97c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_52 (Conv2D)          (None, 48, 48, 8)         80        \n",
      "                                                                 \n",
      " conv2d_53 (Conv2D)          (None, 48, 48, 8)         584       \n",
      "                                                                 \n",
      " max_pooling2d_20 (MaxPoolin  (None, 24, 24, 8)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_54 (Conv2D)          (None, 24, 24, 16)        1168      \n",
      "                                                                 \n",
      " conv2d_55 (Conv2D)          (None, 24, 24, 16)        2320      \n",
      "                                                                 \n",
      " max_pooling2d_21 (MaxPoolin  (None, 12, 12, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_56 (Conv2D)          (None, 12, 12, 32)        4640      \n",
      "                                                                 \n",
      " conv2d_57 (Conv2D)          (None, 12, 12, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_58 (Conv2D)          (None, 12, 12, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_22 (MaxPoolin  (None, 6, 6, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_59 (Conv2D)          (None, 6, 6, 64)          18496     \n",
      "                                                                 \n",
      " conv2d_60 (Conv2D)          (None, 6, 6, 64)          36928     \n",
      "                                                                 \n",
      " conv2d_61 (Conv2D)          (None, 6, 6, 64)          36928     \n",
      "                                                                 \n",
      " max_pooling2d_23 (MaxPoolin  (None, 3, 3, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_62 (Conv2D)          (None, 3, 3, 64)          36928     \n",
      "                                                                 \n",
      " conv2d_63 (Conv2D)          (None, 3, 3, 64)          36928     \n",
      "                                                                 \n",
      " conv2d_64 (Conv2D)          (None, 3, 3, 64)          36928     \n",
      "                                                                 \n",
      " max_pooling2d_24 (MaxPoolin  (None, 1, 1, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 256)               16640     \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 25)                3225      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 283,185\n",
      "Trainable params: 283,185\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_path=\"./model_t/vgg/\"+str(25)+str(arg)+\"/\"\n",
    "model=tf.keras.models.load_model(model_path)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c812159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.35438716411590576, 'accuracy': 0.9039999842643738}\n",
      "{'loss': 0.12396139651536942, 'accuracy': 0.9621142745018005}\n",
      "{'loss': 0.2883799374103546, 'accuracy': 0.9232000112533569}\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "o_t_test=onehot_encoder.fit_transform(t_test).toarray()\n",
    "print(model.evaluate(x_test,o_t_test,verbose=0,return_dict=True))\n",
    "print(model.evaluate(x_train_all,o_t_train,verbose=0,return_dict=True))\n",
    "print(model.evaluate(x_validation_all,o_t_validation,verbose=0,return_dict=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86d14b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpmrvm0hfl/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpmrvm0hfl/assets\n",
      "2024-01-02 08:53:29.886673: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n",
      "2024-01-02 08:53:29.886708: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n",
      "2024-01-02 08:53:29.887660: I tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: /tmp/tmpmrvm0hfl\n",
      "2024-01-02 08:53:29.892968: I tensorflow/cc/saved_model/reader.cc:81] Reading meta graph with tags { serve }\n",
      "2024-01-02 08:53:29.892993: I tensorflow/cc/saved_model/reader.cc:122] Reading SavedModel debug info (if present) from: /tmp/tmpmrvm0hfl\n",
      "2024-01-02 08:53:29.907238: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled\n",
      "2024-01-02 08:53:29.910403: I tensorflow/cc/saved_model/loader.cc:230] Restoring SavedModel bundle.\n",
      "2024-01-02 08:53:30.007217: I tensorflow/cc/saved_model/loader.cc:214] Running initialization op on SavedModel bundle at path: /tmp/tmpmrvm0hfl\n",
      "2024-01-02 08:53:30.046386: I tensorflow/cc/saved_model/loader.cc:321] SavedModel load for tags { serve }; Status: success: OK. Took 158730 microseconds.\n",
      "2024-01-02 08:53:30.105483: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp6v_r19qe/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp6v_r19qe/assets\n",
      "/usr/local/lib/python3.8/dist-packages/tensorflow/lite/python/convert.py:766: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
      "2024-01-02 08:53:34.303110: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n",
      "2024-01-02 08:53:34.303143: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n",
      "2024-01-02 08:53:34.303363: I tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: /tmp/tmp6v_r19qe\n",
      "2024-01-02 08:53:34.309499: I tensorflow/cc/saved_model/reader.cc:81] Reading meta graph with tags { serve }\n",
      "2024-01-02 08:53:34.309525: I tensorflow/cc/saved_model/reader.cc:122] Reading SavedModel debug info (if present) from: /tmp/tmp6v_r19qe\n",
      "2024-01-02 08:53:34.327513: I tensorflow/cc/saved_model/loader.cc:230] Restoring SavedModel bundle.\n",
      "2024-01-02 08:53:34.427843: I tensorflow/cc/saved_model/loader.cc:214] Running initialization op on SavedModel bundle at path: /tmp/tmp6v_r19qe\n",
      "2024-01-02 08:53:34.468824: I tensorflow/cc/saved_model/loader.cc:321] SavedModel load for tags { serve }; Status: success: OK. Took 165462 microseconds.\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: 9, output_inference_type: 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original model the correct nuber is 4520 / total number 5000 = accuracy = 0.904000\n",
      "no quantization model the correct nuber is 4520 / total number 5000 = accuracy = 0.904000\n",
      "quantization model the correct nuber is 4399 / total number 5000 = accuracy = 0.879800\n"
     ]
    }
   ],
   "source": [
    "def predict_tflite_path(tflite_model, x_test):\n",
    "    # Prepare the test data\n",
    "    x_test_ = x_test.copy()\n",
    "    #x_test_ = x_test_.reshape(x_test.size,48,48,1)\n",
    "    \n",
    "    \n",
    "    # Initialize the TFLite interpreter\n",
    "    interpreter = tf.lite.Interpreter(model_path=tflite_model)\n",
    "    interpreter.allocate_tensors()\n",
    "    input_details = interpreter.get_input_details()[0]\n",
    "    output_details = interpreter.get_output_details()[0]\n",
    "    \n",
    "    # If required, quantize the input layer (from float to integer)\n",
    "    input_scale, input_zero_point = input_details[\"quantization\"]\n",
    "    if (input_scale, input_zero_point) != (0.0, 0):\n",
    "        x_test_ = x_test_ / input_scale + input_zero_point\n",
    "        x_test_ = x_test_.astype(input_details[\"dtype\"])\n",
    "    \n",
    "    # Invoke the interpreter\n",
    "    y_pred = np.empty([x_test.shape[0],target_cnt], dtype=output_details[\"dtype\"])\n",
    "    \n",
    "    for i in range(len(x_test_)):\n",
    "        interpreter.set_tensor(input_details[\"index\"], [x_test_[i]])\n",
    "        interpreter.invoke()\n",
    "        y_pred[i] = interpreter.get_tensor(output_details[\"index\"])[0]\n",
    "    \n",
    "    # If required, dequantized the output layer (from integer to float)\n",
    "    output_scale, output_zero_point = output_details[\"quantization\"]\n",
    "    if (output_scale, output_zero_point) != (0.0, 0):\n",
    "        y_pred = y_pred.astype(np.float32)\n",
    "        y_pred = (y_pred - output_zero_point) * output_scale\n",
    "    return y_pred\n",
    "def predict_tflite(tflite_model, x_test,target_cnt):\n",
    "    # Prepare the test data\n",
    "    x_test_ = x_test.copy()\n",
    "    #x_test_ = x_test_.reshape(x_test.size,48,48,1)\n",
    "    \n",
    "    \n",
    "    # Initialize the TFLite interpreter\n",
    "    interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
    "    interpreter.allocate_tensors()\n",
    "    input_details = interpreter.get_input_details()[0]\n",
    "    output_details = interpreter.get_output_details()[0]\n",
    "    \n",
    "    # If required, quantize the input layer (from float to integer)\n",
    "    input_scale, input_zero_point = input_details[\"quantization\"]\n",
    "    if (input_scale, input_zero_point) != (0.0, 0):\n",
    "        x_test_ = x_test_ / input_scale + input_zero_point\n",
    "        x_test_ = x_test_.astype(input_details[\"dtype\"])\n",
    "    \n",
    "    # Invoke the interpreter\n",
    "    y_pred = np.empty([x_test.shape[0],target_cnt], dtype=output_details[\"dtype\"])\n",
    "    \n",
    "    for i in range(len(x_test_)):\n",
    "        interpreter.set_tensor(input_details[\"index\"], [x_test_[i]])\n",
    "        interpreter.invoke()\n",
    "        y_pred[i] = interpreter.get_tensor(output_details[\"index\"])[0]\n",
    "    \n",
    "    # If required, dequantized the output layer (from integer to float)\n",
    "    output_scale, output_zero_point = output_details[\"quantization\"]\n",
    "    if (output_scale, output_zero_point) != (0.0, 0):\n",
    "        y_pred = y_pred.astype(np.float32)\n",
    "        y_pred = (y_pred - output_zero_point) * output_scale\n",
    "    return y_pred\n",
    "\n",
    "def accuracy(name,pred,test):\n",
    "    accuracy=0\n",
    "    for i in range(len(test)):\n",
    "        if pred[i].argmax() == test[i]:\n",
    "            accuracy+=1\n",
    "    print(name+\" model the correct nuber is %d / total number %d = accuracy = %lf\"%(accuracy,len(test),accuracy/len(test)) )\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "model_no_quant_tflite = converter.convert()\n",
    "\n",
    "# Save the model to disk\n",
    "open(model_path+\"noquant.tflite\", \"wb\").write(model_no_quant_tflite)\n",
    "# # Convert the model to the TensorFlow Lite format with quantization\n",
    "def representative_dataset():\n",
    "    for i in range(len(x_test)):\n",
    "        yield([x_test[i].reshape(1,48, 48,1)])\n",
    "\n",
    "# Set the optimization flag.\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "# Enforce integer only quantization\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8\n",
    "converter.inference_output_type = tf.int8\n",
    "# Provide a representative dataset to ensure we quantize correctly.\n",
    "converter.representative_dataset = representative_dataset\n",
    "model_tflite = converter.convert()\n",
    "\n",
    "# Save the model to disk\n",
    "open(model_path+\"ptqi.tflite\", \"wb\").write(model_tflite)\n",
    "y_test_pred_tf = model.predict(x_test)\n",
    "y_test_pred_no_quant_tflite = predict_tflite(model_no_quant_tflite, x_test,25)\n",
    "y_test_pred_tflite = predict_tflite(model_tflite, x_test,25)\n",
    "accuracy(\"original\",y_test_pred_tf,t_test)\n",
    "accuracy(\"no quantization\",y_test_pred_no_quant_tflite,t_test)\n",
    "accuracy(\"quantization\",y_test_pred_tflite,t_test)\n",
    "!xxd -i {model_path+\"ptqi.tflite\"} > {model_path+\"./ptqi.cc\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79058c07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
